{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ba37ZsbEUF",
   "metadata": {
    "id": "c7ba37ZsbEUF"
   },
   "source": [
    "## Importation des Librairies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d97df39",
   "metadata": {
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1655579656825,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "4d97df39"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import walk #generate the file names in a directory tree\n",
    "#it returns a tuple of (root => return directories  ,dirs=> sub directories from the root , files=> files from the subdir specified )\n",
    "from os.path import join\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer #lib used to reduce a word to its base word\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import re #regular expression module \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,f1_score,precision_score,recall_score\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3xHgvN6mQi7I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5285,
     "status": "ok",
     "timestamp": 1655579662812,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "3xHgvN6mQi7I",
    "outputId": "086562da-4d34-48aa-a2e2-51bd39ad9009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N7f3Vm4xbQcn",
   "metadata": {
    "id": "N7f3Vm4xbQcn"
   },
   "source": [
    "## Afin de recuperer les exemples demail , on precise le path des deux types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e29138d",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1655579662814,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "6e29138d"
   },
   "outputs": [],
   "source": [
    "\n",
    "easy_ham_path=\"/content/drive/MyDrive/Colab Notebooks/Projet/easy_ham\" #set the path for hams\n",
    "spam_path=\"/content/drive/MyDrive/Colab Notebooks/Projet/spam\" #set the path for spams\n",
    "\n",
    "spam_class = 1  # spam class \n",
    "ham_class = 0# ham class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OYvFXif5baVx",
   "metadata": {
    "id": "OYvFXif5baVx"
   },
   "source": [
    "## Recuperation du body seulement:\n",
    "Le corp d'un mail se trouve habituellement apres le premier saut de ligne , c'est ce que nous allons utiliser pour le recuperer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d71b423",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1655579662815,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "4d71b423"
   },
   "outputs": [],
   "source": [
    "#for each email get the body only  \n",
    "def get_email_body(path):\n",
    "    #for each file in the directory \n",
    "    for root, dirs, files in walk(path):\n",
    "        for file in files:\n",
    "            #for each file joining the root with its name so that we can have the full path\n",
    "            filepath = join(root, file)\n",
    "            #set encoding to latin-1  \n",
    "            stream = open(filepath, encoding='latin-1') # reading the file \n",
    "            is_body = False\n",
    "            lines = []\n",
    "            #the body starts after a '\\n'\n",
    "            for line in stream:\n",
    "                if is_body:\n",
    "                    lines.append(line) #starts getting the text only after '\\n' \n",
    "                elif line == '\\n':\n",
    "                    is_body = True\n",
    "\n",
    "            email_body = '\\n'.join(lines)\n",
    "            yield file, email_body\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wnaClC4cj8wM",
   "metadata": {
    "id": "wnaClC4cj8wM"
   },
   "source": [
    "## Regrouper les mails dans une seule dataframe avec leurs classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33d5fcdc",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1655579662820,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "33d5fcdc"
   },
   "outputs": [],
   "source": [
    "# put everything in a dataframe (array)\n",
    "def group_emails_df(path, classification):\n",
    "    body = []\n",
    "    name = []\n",
    "#saving the body of each email in a dataframe (indexes=names) \n",
    "    for file, email_body in get_email_body(path):\n",
    "        body.append({'Body':email_body, 'Class': classification})\n",
    "        name.append(file)\n",
    "    return pd.DataFrame(body, index = name)#refer to each email body by the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7f8931e",
   "metadata": {
    "executionInfo": {
     "elapsed": 4769,
     "status": "ok",
     "timestamp": 1655579667571,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "f7f8931e"
   },
   "outputs": [],
   "source": [
    "#Spam Folders\n",
    "spam_emails = group_emails_df(spam_path,spam_class)\n",
    "#Ham Folders\n",
    "ham_emails = group_emails_df(easy_ham_path,ham_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6b1cfab",
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1655579667575,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "e6b1cfab"
   },
   "outputs": [],
   "source": [
    "#print to see one email only \n",
    "#one_email=spam_emails.loc['0001.bfc8d64d12b325ff385cca8d07b84288']\n",
    "#one_email.Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "307d38b2",
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1655579667578,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "307d38b2"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([spam_emails,ham_emails])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bRzMwU0WkL4v",
   "metadata": {
    "id": "bRzMwU0WkL4v"
   },
   "source": [
    "## Partie NLP:\n",
    "Nettoyage des emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a67b08a2",
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1655579667581,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "a67b08a2"
   },
   "outputs": [],
   "source": [
    "#Nettoyage dâ€™emails\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def clean_text(email):\n",
    "    documents = []\n",
    "    stemmer = PorterStemmer()\n",
    "    snow_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    " \n",
    "    for i in range(0,len(email)):\n",
    "         #get rid of all HTML tags by extracting the text only\n",
    "        soup = BeautifulSoup(email[i], 'html.parser') \n",
    "        content = soup.get_text()\n",
    "        \n",
    "         # Converting to Lowercase\n",
    "        content = content.lower()\n",
    "        #replace URLs\n",
    "        content= re.sub('(http|https)://[^\\s]*', 'httpaddr', content)\n",
    "        \n",
    "        #replace email adresses\n",
    "        content= re.sub('[^\\s]+@[^\\s]+', 'emailaddr', content)\n",
    "        \n",
    "        #replace numbers\n",
    "        content= re.sub('[0-9]+', 'number',content)\n",
    "        # replace dollar sign\n",
    "        content=  re.sub('[$]+', 'dollar', content)\n",
    "        \n",
    "        # Remove all the special characters\n",
    "        content = re.sub(r'\\W+', ' ', str(content))\n",
    "        content = re.sub(r\"[^a-zA-Z0-9]+\", ' ', content)\n",
    "\n",
    "        # remove all single characters\n",
    "        content = re.sub(r'\\s+[a-zA-Z]\\s+', ' ',  content)\n",
    "\n",
    "        # Remove single characters from the start\n",
    "        content = re.sub(r'\\^[a-zA-Z]\\s+', ' ', content) \n",
    "\n",
    "        # repalce multiple spaces with single space\n",
    "        content = re.sub(r'\\s+', ' ', content, flags=re.I)\n",
    "\n",
    "        # Lemmatization\n",
    "        content = content.split()\n",
    "        #content = [snow_stemmer.stem(word) for word in content]\n",
    "        content = [stemmer.stem(word) for word in content]\n",
    "        content = ' '.join(content)\n",
    "        \n",
    "     \n",
    "        \n",
    "\n",
    "        documents.append(content)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b5c2456",
   "metadata": {
    "executionInfo": {
     "elapsed": 25232,
     "status": "ok",
     "timestamp": 1655585224478,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "0b5c2456"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Msg = clean_text(data.Body)\n",
    "data.Body = Msg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-WVZ9fWWkYU-",
   "metadata": {
    "id": "-WVZ9fWWkYU-"
   },
   "source": [
    "## Traitement et vectorisation des emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "23b48a1b",
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1655579685483,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "23b48a1b"
   },
   "outputs": [],
   "source": [
    "def create_vocabList(num):\n",
    "    vocab={}\n",
    "    for content in data[data['Class']==spam_class].Body:\n",
    "        words= content.split()\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                vocab[word]=vocab[word]+1\n",
    "            else :\n",
    "                vocab[word]=1\n",
    "\n",
    "    stream= open('vocab.txt','w')\n",
    "    for word in vocab:\n",
    "        if (vocab[word] >= num ):\n",
    "            stream.write(word)\n",
    "            stream.write(\" \")\n",
    "    stream.close  \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "faba8726",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1655579685485,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "faba8726"
   },
   "outputs": [],
   "source": [
    "def getVocabList():\n",
    "    \"\"\"\n",
    "    Reads the fixed vocabulary list in vocab.txt\n",
    "    and returns a dictionary of the words in vocabList.\n",
    "    \"\"\"\n",
    "  \n",
    "    with open('/content/drive/MyDrive/Colab Notebooks/Projet/vocab.txt', 'r') as vocab:\n",
    "        \n",
    "        # Store all dictionary words in dictionary vocabList.\n",
    "        vocabList = {}\n",
    "        for line in vocab.readlines():\n",
    "            words = line.split()\n",
    "            for w in words:\n",
    "                vocabList[w] = words.index(w)\n",
    "\n",
    "    return vocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40108b28",
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1655579685486,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "40108b28"
   },
   "outputs": [],
   "source": [
    "#get the vocab list \n",
    "#split the email into an array of words\n",
    "#for each word , if it exists in vocab list then store its index in the word_indices array \n",
    "def tokenize(email):\n",
    "    vocabList = getVocabList()\n",
    "    email_words= email.split()\n",
    "    word_indices = []\n",
    "    for word in email_words:\n",
    "        if word in vocabList:\n",
    "            idx=vocabList[word]\n",
    "            word_indices.append(idx)\n",
    "    return word_indices\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07cc8caa",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1655579685488,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "07cc8caa"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extraction(email):\n",
    "    vocabList = getVocabList()\n",
    "    n= len(vocabList)\n",
    "    x = np.zeros((1, n))\n",
    "\n",
    "    word_indices= tokenize(email)\n",
    "    for idx in word_indices:\n",
    "    # Assign 1 to index idx in x.\n",
    "        x[0][idx] = 1\n",
    "\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80c391d8",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1655579685489,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "80c391d8"
   },
   "outputs": [],
   "source": [
    "#create a vocab.txt file containing only the words repeated more than a 100 times in spam emails \n",
    "create_vocabList(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40d790d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1655579685491,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "40d790d5",
    "outputId": "ca8366b1-c7d8-4e84-d24c-ded66adc4a2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all the words from vocab.txt\n",
    "vocabList= getVocabList()\n",
    "idc=tokenize(data.loc['0001.bfc8d64d12b325ff385cca8d07b84288'].Body)\n",
    "x=extraction(data.loc['0001.bfc8d64d12b325ff385cca8d07b84288'].Body)\n",
    "len(vocabList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cce766a5",
   "metadata": {
    "executionInfo": {
     "elapsed": 11387,
     "status": "ok",
     "timestamp": 1655579696844,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "cce766a5"
   },
   "outputs": [],
   "source": [
    "#turn all emails into vectors \n",
    "def all_emails_extra(data):\n",
    "    mails=[]\n",
    "    for i in range(0,len(data)):\n",
    "        x= extraction(data[i])\n",
    "        #print(x)\n",
    "        mails.append(x)\n",
    "    y=np.array(mails)\n",
    "    y= np.asmatrix(y)\n",
    "   # print(y)\n",
    "    return y\n",
    "x=all_emails_extra(data.Body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84001cd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1655579696849,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "84001cd8",
    "outputId": "07d3c7fe-59b6-4410-c229-fd2f3297b2ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3052, 266)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9VMKPKdLkg9n",
   "metadata": {
    "id": "9VMKPKdLkg9n"
   },
   "source": [
    "## Partie Tests:\n",
    "Ici nous allons tester avec les differents models vu durant le semestre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "977f0938",
   "metadata": {
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1655579696850,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "977f0938"
   },
   "outputs": [],
   "source": [
    "#Split data\n",
    "X_train, X_test,y_train,y_test = train_test_split(x,data.Class, test_size =0.3, random_state=0)\n",
    "\n",
    "#X_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fYUNQJkhwGG",
   "metadata": {
    "id": "2fYUNQJkhwGG"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e9e77b58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1655579696850,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "e9e77b58",
    "outputId": "236bb1fb-1d02-45d0-8147-ddc8e791999a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM is: 0.9716\n",
      "F1 score:: 0.9121621621621622\n",
      "precision score: 0.9246575342465754\n",
      "recall_score: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "C = 0.1\n",
    "#y = y.ravel()\n",
    "clf = SVC(kernel='linear').fit(X_train, y_train)\n",
    "y_predicted_SVM = clf.predict(X_test)\n",
    "\n",
    "scores_SVM = precision_recall_fscore_support(y_test,y_predicted_SVM)\n",
    "print(\"Accuracy of SVM is:\",round(clf.score(X_test,y_test),4))\n",
    "print('F1 score::',f1_score(y_test, y_predicted_SVM))\n",
    "print('precision score:',precision_score(y_test, y_predicted_SVM))\n",
    "print('recall_score:',recall_score(y_test, y_predicted_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m10C4OEiStsr",
   "metadata": {
    "id": "m10C4OEiStsr"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_y, test_prediction_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nk-zibmygPtj",
   "metadata": {
    "id": "nk-zibmygPtj"
   },
   "source": [
    "# MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf058741",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1655579696851,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "bf058741"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99744bcc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2917,
     "status": "ok",
     "timestamp": 1655579699721,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "99744bcc",
    "outputId": "ebe87fa3-c216-4098-9409-5470b8ad6a24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Neural Network is: 97.27074235807859\n",
      "Confusion Matrix\n",
      "[[755  11]\n",
      " [ 14 136]]\n",
      "F1 score:: 0.9158249158249158\n",
      "precision score: 0.9251700680272109\n",
      "recall_score: 0.9066666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "NN = MLPClassifier()\n",
    "NN.fit(X_train, y_train)\n",
    "y_pred = NN.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print(\"Accuracy for Neural Network is:\",accuracy)\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_mat)\n",
    "print('F1 score::',f1_score(y_test, y_pred))\n",
    "print('precision score:',precision_score(y_test, y_pred))\n",
    "print('recall_score:',recall_score(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rwmHzXKbf_WG",
   "metadata": {
    "id": "rwmHzXKbf_WG"
   },
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "UNdd7VkXOiCl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1655579699723,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "UNdd7VkXOiCl",
    "outputId": "028cc8f4-93eb-43ee-cca6-b92e94779805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8897379912663755\n",
      "F1 score:: 0.705539358600583\n",
      "precision score: 0.6269430051813472\n",
      "recall_score: 0.8066666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(gnb.score(X_test,y_test))\n",
    "print('F1 score::',f1_score(y_test, y_pred))\n",
    "print('precision score:',precision_score(y_test, y_pred))\n",
    "print('recall_score:',recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "TbxwpdqsgWYD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1655579725392,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "TbxwpdqsgWYD",
    "outputId": "d6057089-9a3c-4af3-cd33-bb98fc87c11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596069868995634\n",
      "F1 score:: 0.8802588996763754\n",
      "precision score: 0.8553459119496856\n",
      "recall_score: 0.9066666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "y_pred = mnb.fit(X_train, y_train).predict(X_test)\n",
    "print(mnb.score(X_test,y_test))\n",
    "print('F1 score::',f1_score(y_test, y_pred))\n",
    "print('precision score:',precision_score(y_test, y_pred))\n",
    "print('recall_score:',recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rPfV_05ghUCh",
   "metadata": {
    "id": "rPfV_05ghUCh"
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rbcmiGhohnWs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1655576209816,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "rbcmiGhohnWs",
    "outputId": "84ef11f3-4112-48a9-f75f-4d26c5aec4fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6579639689805565"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lReg = LinearRegression().fit(X_train, y_train)\n",
    "lReg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "izCVn4D2i6g6",
   "metadata": {
    "id": "izCVn4D2i6g6"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fGFxDgewiAxN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1655576104255,
     "user": {
      "displayName": "Zahoua Aoun",
      "userId": "13344578284549564300"
     },
     "user_tz": -120
    },
    "id": "fGFxDgewiAxN",
    "outputId": "4d109531-8f9e-4c57-8764-bdf78dce6a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:: 0.9278350515463918\n",
      "precision score: 0.9574468085106383\n",
      "recall_score: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9770742358078602"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print('F1 score::',f1_score(y_test, y_pred))\n",
    "print('precision score:',precision_score(y_test, y_pred))\n",
    "print('recall_score:',recall_score(y_test, y_pred))\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GAaB8kqSjlw-",
   "metadata": {
    "id": "GAaB8kqSjlw-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "projetAARN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
